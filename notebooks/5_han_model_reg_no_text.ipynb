{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression, Numeric and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../data'))\n",
    "import pathlib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = pathlib.Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_json_paths = list(data_root.glob('*.json'))\n",
    "all_json_paths = [str(path) for path in all_json_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/Kickstarter_2019-01-17T03_20_02_630Z.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_json_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for line in open(all_json_paths[0], 'r', encoding='utf8'):\n",
    "    data.append(json.loads(line))\n",
    "    \n",
    "data = [record['data'] for record in data]\n",
    "raw = pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Naive preprocessing the input data by dropping samples that still have the campaign running,\n",
    "    impute durations and categories, dropping unnecessary features, and one-hot encoding for\n",
    "    training.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "    \"\"\"\n",
    "    # get durations by taking the difference between launch and deadline and transform\n",
    "    # the seconds integer into days.\n",
    "    df['durations'] = round((df.deadline - df.launched_at)/(60*60*24))\n",
    "    \n",
    "    # parse the category feature's json format and extract the first level categories\n",
    "    df['cat_slug'] = df.category.apply(lambda x: x['slug'].split('/')[0])\n",
    "\n",
    "    # map states to 1 for success and 0 for others. Also will drop all 'live' records.\n",
    "    state_dict = {'successful':1, 'failed':0, 'canceled':0, 'suspended':0}\n",
    "    df = df.replace({\"state\": state_dict})\n",
    "    df = df[df.state != 'live']\n",
    "\n",
    "    # drop unused features\n",
    "    df = df[['name', 'blurb', 'goal', 'country', 'durations', 'cat_slug', 'state']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Linear Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((172516, 2), (30444, 2), (172516,), (30444,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_names = raw.columns.to_list()\n",
    "X_col = ['goal', 'durations']#, 'country', 'cat_slug']\n",
    "df = raw.copy()\n",
    "df = preproc(df)\n",
    "X = df[X_col].to_numpy()\n",
    "# need to add .astype('int') to turn it y into int from object. otherise sklearn wont work\n",
    "# https://stackoverflow.com/questions/45346550/valueerror-unknown-label-type-unknown\n",
    "y = df.state.to_numpy().astype('int')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=45)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 ms, sys: 355 Âµs, total: 15.3 ms\n",
      "Wall time: 17.7 ms\n",
      "R^2 score of the model is: 0.026041726661496956\n",
      "Mean square error is: 38379720612.492325\n"
     ]
    }
   ],
   "source": [
    "# normalize X_train\n",
    "X_train = (X_train - X_train.mean())/X_train.std()\n",
    "\n",
    "%time clf = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print(f\"R^2 score of the model is: {clf.score(X_train, y_train)}\")\n",
    "y_pred = clf.predict(X_test)#train[0].reshape(1, -1))\n",
    "print(f\"Mean square error is: {mean_squared_error(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((172516, 4), (30444, 4), (172516,), (30444,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_names = raw.columns.to_list()\n",
    "X_col = ['goal', 'durations', 'country', 'cat_slug']\n",
    "df = raw.copy()\n",
    "df = preproc(df)\n",
    "X = df[X_col].to_numpy()\n",
    "# need to add .astype('int') to turn it y into int from object. otherise sklearn wont work\n",
    "# https://stackoverflow.com/questions/45346550/valueerror-unknown-label-type-unknown\n",
    "y = df.state.to_numpy().astype('int')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=45)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(X, y):\n",
    "    \"\"\"\n",
    "    Logistic regression model using GridSearchCV. Since GridSearchCV does cross validation internally,\n",
    "    we choose not to split X into training and validation set. We choose to do 5 fold cross validation\n",
    "    during GridSearch. With that, data issplit three ways: 0.68 train, 0.17 validation, and 0.15 test.\n",
    "    We will continue to use OneHotEncoding and StandardScaler in our training pipeline. Since some of\n",
    "    the categorical features have very high cardinality, e.g., funder with 1898 categories, we choose\n",
    "    to take only the top 6 with high cardinality to reduce training time.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : training data\n",
    "    y : target data\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    search.best_estimator : the best Logistic Regression model produced by the GridSearchCV\n",
    "    \"\"\"\n",
    "\n",
    "    reg = SGDRegressor()#solver='lbfgs', multi_class='ovr', random_state=45, max_iter=500)\n",
    "    encoder = OneHotEncoder(categories='auto', handle_unknown='ignore')\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "    pipe = Pipeline(steps=[('encoder', encoder),\n",
    "                           ('scaler', scaler),\n",
    "                           ('reg', reg)\n",
    "                           ])\n",
    "    \n",
    "    param_grid = {\n",
    "        'reg__l1_ratio': np.arange(0.15, 0.80, 0.05),\n",
    "    }\n",
    "    \n",
    "    search = GridSearchCV(pipe, param_grid, n_jobs=-1, cv=5)\n",
    "    %time search.fit(X, y)\n",
    "    print(\"Training Score (accuracy): {}\".format(search.best_score_))\n",
    "    print(\"Best Parameters: {}\".format(search.best_params_))\n",
    "    \n",
    "    return search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.1 s, sys: 1.41 s, total: 19.5 s\n",
      "Wall time: 21.5 s\n",
      "Training Score (accuracy): -2.4100745789599384e+25\n",
      "Best Parameters: {'reg__l1_ratio': 0.3500000000000001}\n"
     ]
    }
   ],
   "source": [
    "model = regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.654150148975187e+25"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score of the model is: -8.848398892410494e+25\n",
      "Mean square error is: 1.3770090363515053e+25\n"
     ]
    }
   ],
   "source": [
    "print(f\"R^2 score of the model is: {model.score(X_train, y_train)}\")\n",
    "y_pred = model.predict(X_test)#train[0].reshape(1, -1))\n",
    "print(f\"Mean square error is: {mean_squared_error(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neither regression produced meaningful results. Will use logistic regression's predict probability output instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
