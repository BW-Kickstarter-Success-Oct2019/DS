{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Baseline, Numeric Features Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../data'))\n",
    "import pathlib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = pathlib.Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_json_paths = list(data_root.glob('*.json'))\n",
    "all_json_paths = [str(path) for path in all_json_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/Kickstarter_2019-01-17T03_20_02_630Z.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_json_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for line in open(all_json_paths[0], 'r', encoding='utf8'):\n",
    "    data.append(json.loads(line))\n",
    "    \n",
    "data = [record['data'] for record in data]\n",
    "raw = pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Naive preprocessing the input data by dropping samples that still have the campaign running,\n",
    "    impute durations and categories, dropping unnecessary features, and one-hot encoding for\n",
    "    training.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "    \"\"\"\n",
    "    # get durations by taking the difference between launch and deadline and transform\n",
    "    # the seconds integer into days.\n",
    "    df['durations'] = round((df.deadline - df.launched_at)/(60*60*24))\n",
    "    \n",
    "    # parse the category feature's json format and extract the first level categories\n",
    "    df['cat_slug'] = df.category.apply(lambda x: x['slug'].split('/')[0])\n",
    "\n",
    "    # map states to 1 for success and 0 for others. Also will drop all 'live' records.\n",
    "    state_dict = {'successful':1, 'failed':0, 'canceled':0, 'suspended':0}\n",
    "    df = df.replace({\"state\": state_dict})\n",
    "    df = df[df.state != 'live']\n",
    "\n",
    "    # drop unused features\n",
    "    df = df[['name', 'blurb', 'goal', 'country', 'durations', 'cat_slug', 'state']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_names = raw.columns.to_list()\n",
    "X_col = ['goal', 'durations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw.copy()\n",
    "df = preproc(df)\n",
    "X = df[X_col]\n",
    "# need to add .astype('int') to turn it y into int from object. otherise sklearn wont work\n",
    "# https://stackoverflow.com/questions/45346550/valueerror-unknown-label-type-unknown\n",
    "y = df.state.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((172516, 2), (30444, 2), (172516,), (30444,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=45)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.08 s, sys: 1.4 s, total: 3.48 s\n",
      "Wall time: 965 ms\n"
     ]
    }
   ],
   "source": [
    "%time clf = LogisticRegression(random_state=45, solver='lbfgs', multi_class='ovr').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.605669425831034"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "goal         600.0\n",
       "durations     22.0\n",
       "Name: 107035, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test.iloc[0].to_numpy().reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our target is (0, 1), the classifier would output a probability matrix of dimension (N, 2). The first index refers to the probability of belonging to class 0, the second index refers to the probability of belonging to class 1. The two will sum to one. \n",
    "\n",
    "https://datascience.stackexchange.com/questions/22762/understanding-predict-proba-from-multioutputclassifier\n",
    "\n",
    "Thus, the 'chance' of success (1) will be the second component of predict_proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54524918])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test.iloc[0].to_numpy().reshape(1, -1))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
