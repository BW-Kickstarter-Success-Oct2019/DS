{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression, Numeric and Categorical Features Predict Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../data'))\n",
    "import pathlib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = pathlib.Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_json_paths = list(data_root.glob('*.json'))\n",
    "all_json_paths = [str(path) for path in all_json_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\data\\\\Kickstarter_2019-01-17T03_20_02_630Z.json',\n",
       " '..\\\\data\\\\Kickstarter_2019-02-14T03_20_04_734Z.json',\n",
       " '..\\\\data\\\\Kickstarter_2019-03-14T03_20_12_200Z.json',\n",
       " '..\\\\data\\\\Kickstarter_2019-04-18T03_20_02_220Z.json',\n",
       " '..\\\\data\\\\Kickstarter_2019-05-16T03_20_20_822Z.json',\n",
       " '..\\\\data\\\\Kickstarter_2019-06-13T03_20_35_801Z.json',\n",
       " '..\\\\data\\\\Kickstarter_2019-07-18T03_20_05_009Z.json',\n",
       " '..\\\\data\\\\Kickstarter_2019-08-15T03_20_03_022Z.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_json_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for line in open(all_json_paths[0], 'r', encoding='utf8'):\n",
    "    data.append(json.loads(line))\n",
    "    \n",
    "data = [record['data'] for record in data]\n",
    "raw = pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Naive preprocessing the input data by dropping samples that still have the campaign running,\n",
    "    impute durations and categories, dropping unnecessary features, and one-hot encoding for\n",
    "    training.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "    \"\"\"\n",
    "    # get durations by taking the difference between launch and deadline and transform\n",
    "    # the seconds integer into days.\n",
    "    df['durations'] = round((df.deadline - df.launched_at)/(60*60*24))\n",
    "    \n",
    "    # parse the category feature's json format and extract the first level categories\n",
    "    df['cat_slug'] = df.category.apply(lambda x: x['slug'].split('/')[0])\n",
    "\n",
    "    # map states to 1 for success and 0 for others. Also will drop all 'live' records.\n",
    "    state_dict = {'successful':1, 'failed':0, 'canceled':0, 'suspended':0}\n",
    "    df = df.replace({\"state\": state_dict})\n",
    "    df = df[df.state != 'live']\n",
    "\n",
    "    # drop unused features\n",
    "    df = df[['name', 'blurb', 'goal', 'country', 'durations', 'cat_slug', 'state']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_names = raw.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw.copy()\n",
    "df = preproc(df)\n",
    "X_col = ['goal', 'durations', 'country', 'cat_slug']\n",
    "X = df[X_col]\n",
    "# need to add .astype('int') to turn it y into int from object. otherise sklearn wont work\n",
    "# https://stackoverflow.com/questions/45346550/valueerror-unknown-label-type-unknown\n",
    "y = df.state.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((172516, 4), (30444, 4), (172516,), (30444,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), y.to_numpy(), test_size=0.15, random_state=45)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X, y):\n",
    "    \"\"\"\n",
    "    Logistic regression model using GridSearchCV. Since GridSearchCV does cross validation internally,\n",
    "    we choose not to split X into training and validation set. We choose to do 5 fold cross validation\n",
    "    during GridSearch. With that, data issplit three ways: 0.68 train, 0.17 validation, and 0.15 test.\n",
    "    We will continue to use OneHotEncoding and StandardScaler in our training pipeline. Since some of\n",
    "    the categorical features have very high cardinality, e.g., funder with 1898 categories, we choose\n",
    "    to take only the top 6 with high cardinality to reduce training time.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : training data\n",
    "    y : target data\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    search.best_estimator : the best Logistic Regression model produced by the GridSearchCV\n",
    "    \"\"\"\n",
    "\n",
    "    logreg = LogisticRegression(solver='lbfgs', multi_class='ovr', random_state=45, max_iter=500)\n",
    "    encoder = OneHotEncoder(categories='auto', handle_unknown='ignore')\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "    pipe = Pipeline(steps=[('encoder', encoder),\n",
    "                           ('scaler', scaler),\n",
    "                           ('logreg', logreg)\n",
    "                           ])\n",
    "    \n",
    "    param_grid = {\n",
    "        'logreg__C': np.power(10.0, np.arange(3, 10)),\n",
    "    }\n",
    "    \n",
    "    search = GridSearchCV(pipe, param_grid, n_jobs=-1, cv=5)\n",
    "    %time search.fit(X, y)\n",
    "    print(\"Training Score (accuracy): {}\".format(search.best_score_))\n",
    "    print(\"Best Parameters: {}\".format(search.best_params_))\n",
    "    \n",
    "    return search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.2 s\n",
      "Training Score (accuracy): 0.6818729856940805\n",
      "Best Parameters: {'logreg__C': 1000.0}\n"
     ]
    }
   ],
   "source": [
    "model = logistic_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6805610300880305"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/20191022_logreg_68.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "test1 = '''{\"name\": \"asdfasdfasdf\", \"blurb\": \"asdfasdfasdfadsdfasdfadfasdf\", \"goal\": 800.0, \"country\": \"US\", \"duration\":15.0, \"category\": \"fashion\"}'''\n",
    "test2 = '''{\"goal\": 800.0, \"country\": \"US\", \"duration\":15.0, \"category\": \"fashion\"}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5147114])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1j = json.loads(test2)\n",
    "test1df = pd.DataFrame.from_records(test1j, index=[0])\n",
    "model.predict_proba(test1df.to_numpy())[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Distributionof testing data\n",
    "Look at the distribution of the prediction for the probability of success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict_proba(X_test)\n",
    "plt.hist(y_pred[:,1], bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest probability w/in test 0.9999999999999978, highest prob sample location is 6371\n",
      "[2011.0 67.0 'US' 'publishing']\n",
      "The highest probabilty sample is [2011.0 67.0 'US' 'publishing'], shape is (4,))\n"
     ]
    }
   ],
   "source": [
    "print(f\"Highest probability w/in test {np.max(y_pred[:,1])}, highest prob sample location is {np.argmax(y_pred[:,1])}\")\n",
    "x_high = X_test[np.argmax(y_pred[:,1])]\n",
    "print(x_high)\n",
    "print(f\"The highest probabilty sample is {x_high}, shape is {x_high.shape})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.22044605e-15, 1.00000000e+00]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x_high.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.22044605e-15, 1.00000000e+00]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test[np.argmax(y_pred[:,1])].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal, duration, country, category = 2011.0, 67.0, 'US', 'publishing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999996])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3 = '''{\"goal\": 2011, \"country\": \"US\", \"duration\":67, \"category\": \"publishing\"}'''\n",
    "test3j = json.loads(test3)\n",
    "test3df = pd.DataFrame.from_records(test3j, index=[0], columns=['goal', 'country', 'duration', 'category'])\n",
    "model.predict_proba(test3df.to_numpy())[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
